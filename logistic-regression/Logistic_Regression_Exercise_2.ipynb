{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWz85gtBxbiQJ7T0QcoZS3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Raptor-sj22/ML-Training/blob/main/logistic-regression/Logistic_Regression_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs logistic regression with 3rd-degree polynomial features using TensorFlow/Keras to classify a synthetic 2D dataset. The input features are expanded using PolynomialFeatures from scikit-learn to capture non-linear relationships. A single-layer neural network with sigmoid activation and L2 regularization (λ = 0.001) is used as the classifier. The model is trained on 300 samples for 200 epochs using the Adam optimizer, binary crossentropy as the loss function, and reports accuracy as a metric. The decision boundary is visualized over a mesh grid, and an interactive threshold slider allows real-time updates to the classification regions."
      ],
      "metadata": {
        "id": "oySeHSX4iYP6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model with a Data set with random pattern\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "#commented this line for githup\n",
        "#import ipywidgets as widgets"
      ],
      "metadata": {
        "id": "8A9GYNKJ-raT"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model with a Data set with random pattern\n",
        "\n",
        "\n",
        "\n",
        "# 1️⃣ Generate a synthetic 2D dataset\n",
        "X, y = make_classification(\n",
        "    n_samples=300, n_features=2,\n",
        "    n_redundant=0, n_informative=2,\n",
        "    n_clusters_per_class=1,\n",
        "    class_sep=1.0, random_state=42\n",
        ")\n",
        "\n",
        "# 2️⃣ Add polynomial features\n",
        "poly = PolynomialFeatures(degree=3, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# 3️⃣ Define a simple regression-based classifier (logistic regression with L2 regularization)\n",
        "model = Sequential([\n",
        "    Dense(1,\n",
        "          input_dim=X_poly.shape[1],\n",
        "          activation='sigmoid',\n",
        "          kernel_regularizer=regularizers.l2(.001))  # L2 regularization (lambda = 0.01)\n",
        "])\n",
        "\n",
        "# 4️⃣ Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5️⃣ Train the model\n",
        "model.fit(X_poly, y, epochs=200, verbose=1)\n",
        "\n",
        "# 6️⃣ Visualize the dataset and decision boundary\n",
        "\n",
        "# Create a mesh grid for plotting decision boundary\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
        "                     np.linspace(y_min, y_max, 300))\n",
        "\n",
        "# Transform grid points to polynomial feature space\n",
        "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "grid_points_poly = poly.transform(grid_points)\n",
        "\n",
        "# Predict probabilities for each grid point\n",
        "Z = model.predict(grid_points_poly)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Predict on training set once (probs are fixed)\n",
        "probs = model.predict(X_poly)\n",
        "\n",
        "def plot_with_threshold(threshold):\n",
        "    # Predict over the mesh grid with current threshold\n",
        "    Z_thresh = (Z > threshold).astype(int)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "\n",
        "    # Background region (prediction)\n",
        "    plt.contourf(xx, yy, Z_thresh, levels=[-1, 0, 1], alpha=0.3, colors=['blue', 'orange'])\n",
        "\n",
        "    # Decision boundary line\n",
        "    plt.contour(xx, yy, Z, levels=[threshold], colors='k', linewidths=1)\n",
        "\n",
        "    # Points: fixed color based on true label (y), NOT threshold\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolors='k', label='Class 0 (true)')\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='orange', edgecolors='k', label='Class 1 (true)')\n",
        "\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.title(f\"Decision Boundary (Threshold = {threshold:.2f})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Interactive threshold slider\n",
        "threshold_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description='Threshold:',\n",
        "    continuous_update=True\n",
        ")\n",
        "\n",
        "# Display the interactive plot\n",
        "widgets.interact(plot_with_threshold, threshold=threshold_slider)"
      ],
      "metadata": {
        "id": "wL4X3aoP_7aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model with a Data set with Circular pattern\n",
        "np.random.seed(42)\n",
        "n_samples = 300\n",
        "\n",
        "# Class 0: points inside the circle (radius < 1)\n",
        "r0 = np.random.rand(n_samples // 2)\n",
        "theta0 = 2 * np.pi * np.random.rand(n_samples // 2)\n",
        "x0 = np.stack([r0 * np.cos(theta0), r0 * np.sin(theta0)], axis=1)\n",
        "\n",
        "# Class 1: points outside the circle (radius between 1.5 and 2.5)\n",
        "r1 = 1.5 + np.random.rand(n_samples // 2)\n",
        "theta1 = 2 * np.pi * np.random.rand(n_samples // 2)\n",
        "x1 = np.stack([r1 * np.cos(theta1), r1 * np.sin(theta1)], axis=1)\n",
        "\n",
        "# Combine\n",
        "X = np.vstack([x0, x1])\n",
        "y = np.array([0] * (n_samples // 2) + [1] * (n_samples // 2))\n",
        "\n",
        "# 2️⃣ Add polynomial features\n",
        "poly = PolynomialFeatures(degree=4, include_bias=False)\n",
        "X_poly = poly.fit_transform(X)\n",
        "\n",
        "# 3️⃣ Define a simple regression-based classifier (logistic regression with L2 regularization)\n",
        "model = Sequential([\n",
        "    Dense(1,\n",
        "          input_dim=X_poly.shape[1],\n",
        "          activation='sigmoid',\n",
        "          kernel_regularizer=regularizers.l2(0.001))\n",
        "])\n",
        "\n",
        "# 4️⃣ Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# 5️⃣ Train the model\n",
        "model.fit(X_poly, y, epochs=100, verbose=1)\n",
        "\n",
        "# 6️⃣ Visualize the dataset and decision boundary\n",
        "\n",
        "# Create a mesh grid for plotting decision boundary\n",
        "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 300),\n",
        "                     np.linspace(y_min, y_max, 300))\n",
        "\n",
        "# Transform grid points to polynomial feature space\n",
        "grid_points = np.c_[xx.ravel(), yy.ravel()]\n",
        "grid_points_poly = poly.transform(grid_points)\n",
        "\n",
        "# Predict probabilities for each grid point\n",
        "Z = model.predict(grid_points_poly)\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Predict on training set once (probs are fixed)\n",
        "probs = model.predict(X_poly)\n",
        "\n",
        "def plot_with_threshold(threshold):\n",
        "    # Predict over the mesh grid with current threshold\n",
        "    Z_thresh = (Z > threshold).astype(int)\n",
        "\n",
        "    plt.figure(figsize=(8,6))\n",
        "\n",
        "    # Background region (prediction)\n",
        "    plt.contourf(xx, yy, Z_thresh, levels=[-1, 0, 1], alpha=0.3, colors=['blue', 'orange'])\n",
        "\n",
        "    # Decision boundary line\n",
        "    plt.contour(xx, yy, Z, levels=[threshold], colors='k', linewidths=1)\n",
        "\n",
        "    # Points: fixed color based on true label (y), NOT threshold\n",
        "    plt.scatter(X[y==0, 0], X[y==0, 1], c='blue', edgecolors='k', label='Class 0 (true)')\n",
        "    plt.scatter(X[y==1, 0], X[y==1, 1], c='orange', edgecolors='k', label='Class 1 (true)')\n",
        "\n",
        "    plt.xlabel(\"Feature 1\")\n",
        "    plt.ylabel(\"Feature 2\")\n",
        "    plt.title(f\"Decision Boundary (Threshold = {threshold:.2f})\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Interactive threshold slider\n",
        "threshold_slider = widgets.FloatSlider(\n",
        "    value=0.5,\n",
        "    min=0.0,\n",
        "    max=1.0,\n",
        "    step=0.01,\n",
        "    description='Threshold:',\n",
        "    continuous_update=True\n",
        ")\n",
        "\n",
        "# Display the interactive plot\n",
        "widgets.interact(plot_with_threshold, threshold=threshold_slider)"
      ],
      "metadata": {
        "id": "HLOGBf2vjeDN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}